# Redis
## 基础知识
### Redis是什么？
redis是一种存放在内存中的数据库，所以读写速度非常快，被广泛应用于缓存方向。也会被用于做分布式锁，还支持LRU驱动事件，多种集群方案。

### 有MySQL不就够用了吗？为什么要用Redis这种新的数据库？
- 	redis的数据存放在内存中，访问速度快
- 	可以承受高并发的访问请求
- 	支持存储的数据类型很多

### 使用Redis的好处有哪些？
- 访问速度快，高并发，读的速度是100000次/s，写的速度是80000次/s
- 	支持多种数据类型
- 	支持事务，即操作都是原子性的
- 	特性丰富，可以用于缓存，并且可以设置key的过期时间

### Redis一般用在什么地方
- 	缓存MySQL中的数据
- 	秒杀场景下，提前把数据放到Redis中
- 	页面预加载和缓存，先加载整体信息，再请求数据

### Memcached与Redis的区别都有哪些？
- 	memcached的所有数据都存放在内存中，因此掉电消失，没有持久性；而redis存在磁盘上，内存中的是它的部分缓存，因此可以保证数据的持久性
- 	memcached只支持key-value的存储，而redis有复杂的数据类型，还提供链表、哈希表等其他结构
- 	value值的大小不同，redis最大可到512MB，而memcached只有1MB
- 	memcached是多线程非阻塞IO复用的网络模型，redis使用单线程的多路IO复用模型
- 	底层实现方式以及与客户端之间通信的应用协议不同：redis有自己的虚拟内存机制，而不是使用系统调用函数
- 	集群模式：memcached没有原生的集群模式，需要依靠客户端往集群中写数据，而redis是原生支持cluster模式的。

### Redis的事务
通过MULTI、EXEC、WATCH等命令来实现事务机制，事务执行过程将一系列多个命令按照顺序一次性执行，在执行期间，事务不会被中断，也不会去执行客户端的其他请求，直到所有命令执行完毕。
- 	服务端收到客户端请求，事务以MULTI开始
- 	如果正处于事务状态时，则会把后续命令放入队列同时返回给客户端QUEUED，反之则直接执行个命令
- 	当收到客户端的EXEC命令时，才会将队列里的命令取出、顺序执行，执行完将当前状态从事务状态改为非事务状态
- 	如果收到 DISCARD 命令，放弃执行队列中的命令，可以理解为Mysql的回滚操作，并且将当前的状态从事务状态改为非事务状态

### Redis中事务的原子性怎么理解？
只要事务中的命令语法正确且能正确执行，就会被原子地执行，如果命令出现错误，则所有的命令都不会执行，如果出现了运行错误，则只执行正确的命令。

### Redis 与 Guava 、Caffeine 有什么区别？
- Caffeine、Guava，属于本地缓存：
	- 直接访问内存，速度快，受内存限制，无法进行大数据存储。
	- 无网络通讯开销，性能更高。
	- 只支持本地应用进程访问，同步更新所有节点的本地缓存数据成本较高。
	- 应用进程重启，数据会丢失。
	- 本地缓存适合存储一些不易改变或者低频改变的高热点数据。
- Redis属于分布式缓存：
	- 集群模式，支持大数据量存储
	- 数据集中存储，保证数据的一致性
	- 数据跨网络传输，性能低于本地缓存。但同一个机房，两台服务器之间请求跑一个来回也就需要500微秒，比起其优势，这点损耗完全可以忽略，这也是分布式缓存受欢迎的原因。
	- 支持副本机制，有效的保证了高可用性。

### Redis事务的实现
- MULTI: 表示事务的开始，在redis中执行这条语句以后，表示事务的开启，这个时候，所输入的命令并不会立马执行下去，相反，在未出现EXEC特殊字符时候，所有命令的执行都会进入一个队列中。
- EXEC：表示对进入到队列的语句进行一个执行操作，执行的是先进先出的原则。
- WATCH： 表示监听，可以监听一个或多个健，是一个乐观锁，一旦其中有一个键被修改（或删除），之后的事务就不会执行，监控一直持续到EXEC命令
- DISCARD： 表示清空事务队列，前面我们提到了事务在未被执行的过程中，都会进入到一个队列中，此条操作就会清空事务队列，并放弃执行事务。

### k-v存储中，key有哪些要求？
非空且不能重复。


 
## 五种数据结构
### Redis常见数据结构以及使用场景分别是什么？
- SDS（简单动态字符串）
用于表示一个字符串，但又不仅仅只能表示字符串，通过构建一个动态数组保存所需要存储的内容，有两个属性，一个是字符串长度，一个是未使用空间长度。有以下特点：
	- 	读取字符串长度信息只需要常数时间，因为这是保存在SDS数据结构中的一个属性，不用遍历整个字符串以获取长度；
	- 	内存安全：执行字符串拼接时，会先检查剩余空间是否充足，如果充足，则直接附着在后面，否则就要重新分配空间；
	- 	减少了重新分配空间的次数：为字符串重新分配空间之后，还会保留一部分的内存，即free字段的值（等于扩展后字符的实际长度），用于以后扩展该字符串，将N次分配空间，变成最多分配N次空间；
	- 	二进制安全：C字符串以\0作为结尾，因此不能存放这些特殊的字符，但是由于SDS以字符串长度作为表示，而不是以\0作为结束的标识，把数据当作二进制来看，因此可以存储其他数据。
	- 	兼容部分C字符串函数，因为SDS也保留了\0作为字符串的结束标志，因此可以复用一些C标准中的字符串函数。
- 链表
是一个双向无环链表，通过一个结构体对链表进行管理，包括头尾节点、节点数量、复制、释放、对比函数指针等，可以实现多态。
- 字典
底层就是一个哈希表，封装成四层结构，第一层是存储了各种函数和私有数据的字典管理结构体，包括了两个哈希表管理结构体的实体，包括了表的大小等信息，一般情况下这两个只会使用一个，只有rehash的情况下才会使用两个。在结构体内还有一个哈希表的实体，是一个指针数组，每一个指针又指向一个具体的地址，即节点，每个地址上的指针都是单链表组织起来的，因此包括键值、实际值和next指针。
发生哈希冲突时，使用链地址法（开链法）解决，新增的节点都放在最前面。
当数据量过大或过小时（used/size），都会进行rehash：
	- 	当没有执行BGSAVE或BGREWRITRAOF时，负载因子大于1；
	- 	执行BGSAVE或BGREWRITRAOF时，负载因子大于5；
	- 	负载因子小于0.1时。
rehash的大小用第一个原hash表使用过的数量*2的第一个2^n的值作为新的哈希表的大小，并用这个数值为ht[1]分配空间，然后将ht[0]的数据迁移到ht[1]处，并且将ht[1]修改为ht[0]。
不同情况下使用不同的负载因子是由于在上述两个操作过程中会创建当前服务器进程的子进程，而服务器提供写时复制，因此应该尽量避免有子进程存在时对数据的修改，从而最大限度地节省内存。
为了解决大数据量rehash耗时的问题，需要使用rehashidx对rehash的进度进行记录，-1表示当前没有rehash，其他值表示当前已经完成了第几个表的rehash，搜索时会在两个表中进行搜索。
- 跳表
跳表是一个有序的集合，每个跳表节点的层高都是一个1到32的随机数，同层之间相连。
多个节点可以有相同的分值，但是每个节点的对象都是唯一的。按分值大小排序，分值相同的按对象大小排序。
- 压缩列表
压缩列表是为了节约内存而开发的顺序型数据结构，以时间换空间。
因为是顺序存储的，所以插入删除查找操作的平均时间复杂度都是O(N)，插入删除操作的最坏时间复杂度都是O(n^2 )，因为这些操作可能会引起连锁更新（在最前面插入一个长度大于254个字节的节点，而后面所有的节点的长度都位于250至253个字节之间，插入第一个节点之后，后面的节点都要改变其前一个节点长度的数值）
因为每个节点包含了前一个节点长度和当前节点编码，所以可以正向和反向遍历。
每个节点可以保存整数或者字符串。
分为五段，分别是整个压缩列表使用的内存字节数（用于对压缩列表进行内存重分配时使用）、列表尾节点距离起始地址的偏移（用于从后向前遍历时确定尾端的位置），列表节点数量、节点、尾端（0xff）
- 整数集合
通过一个结构体，指向一个有序的整数数组，这个结构体中有一个字段表示数据类型（可以是16、32、64位的数据），有个字段表示集合内有多少数据。
当插入了一个超出当前数据位数的数时，需要进行升级操作，即首先扩展数组空间大小，然后将底层数组所有现有元素全部转为新元素相同的类型，把所有的数据全部按顺序放到新的数组中，最后把新元素添加到数组中，并且更新结构体中的信息。

### Redis常见的对象及其适用场景
- 字符串对象
编码类型包括int、raw和embstr三种。
根据存储的值来自动判断使用哪种编码类型，即底层实现：
	- 	如果是一个用long就可以表示的整数，将编码设置为int（这个只是取integer，村的是long类型的数据）
	- 	如果是长度大于39的字符串，就使用raw（也就是SDS）
	- 	如果是长度小于等于39的字符串，就是用embstr
		- 	embstr这种编码是一次内存分配就分配一整块连续的空间用于存放redis对象结构体和sds结构体，而SDS是两次分别创建两个结构体。
		- 	同理，释放也是只调用一次
		- 	embstr会将两个结构体缓存在一块连续的内存里，因此会比SDS更好地利用缓存带来的优势
	- 	如果是long double类型的数据，会将数据转为字符串
	- 	如果对一个int类型的值通过APPEND追加了一个字符串的值，则会从int转为raw
	- 	不能对embstr修改，是只读的，一旦对其进行追加APPEND，则会自动转为raw
- 列表对象
编码方式可以是ziplist或者是linkedlist。
当同时满足以下两个条件时，列表对象使用ziplist编码：
	- 	所有字符串元素的长度都小于64个字节
	- 	保存的元素数量小于512个
否则其他的数据都是以linkedlist编码
- 哈希对象
编码方式可以是hashtable和ziplist
使用ziplist结构存储的需要把键和值分开作为两项来存储，但不保证有序，添加进去的值都之间push到最后面
当哈希对象同时满足以下两个条件时，实例ziplist编码：
	- 	所有键和值的字符串长度都小于64字节
	- 	键值对数量小于512个
- 集合对象
编码方式可以是hashtable和intset
当同时满足以下两种情况时采用intset方式编码：
	- 	保存的所有元素都是整数值
	- 	集合对象保存的元素数量不超过512个
- 有序集合对象
使用ziplist或skiplist编码
其中skiplist的底层是跳表和字典，两者通过指针共享重复成员或者分值
当同时满足以下两种情况时采用ziplist方式编码：
	- 	元素数量小于128
	- 	元素成员长度小于64字节

### Redis中的ziplist为什么会节省内存？能节省多少内存
压缩列表节省内存主要是通过不使用指针而实现的。在链表和哈希表中，都需要一个结构体来存储一个实体，这个实体中大多数都是指针指向一个地址，通常都是24个字节，而在压缩列表中，是在一块连续的内存空间中存储数据，通过偏移量进行数据的寻址，最短1字节，最长也不过5字节，因此在存储非数据部分，压缩列表大大节省了内存。

### 为什么有序集合要同时使用跳表和字典？
- 优化时间复杂度
- 如果只用字典，可以快速找到元素的存储位置，但是由于字典是无序的，所以如果要进行范围查找，时间复杂度就比较高了O(NlogN)。
- 如果只用跳表，那么定位到元素位置的操作会变为O(logN)

### C++中的Map也是一种缓存型数据结构，为什么不用Map，而选择Redis做缓存？
缓存分为本地缓存和分布式缓存。map只能用于做本地缓存，当程序结束，这个map也就会被销毁，多实例的情况下，每个实例都需要各自保存一份缓存，缓存不具有一致性。
redis缓存是分布式缓存，具有持久性和一致性。多实例的情况下共享同一个缓存。

### 为什么不用红黑树而是用跳表
范围查找时，对红黑树来说，找到了最小值之后还要进行中序遍历，但是对于跳表来说，找到了最小值之后直接通过遍历链表就可以找到
插入和删除操作中，红黑树需要进行多次旋转节点操作，而跳表更快一些。

### Redis 常用的 5 种数据结构和应用场景？
String：缓存、计数器、分布式锁等
- List：链表、队列、微博关注人时间轴列表等
- Hash：用户信息、Hash 表等
- Set：去重、赞、踩、共同好友等
- Zset：访问量排行榜、点击量排行榜等

### SortedSet和List异同点？
- 相同点：
	- 都是有序的；
	- 都可以获得某个范围内的元素。
- 不同点：
	- 列表基于链表实现，获取两端元素速度快，访问中间元素速度慢；
	- 有序集合基于散列表和跳跃表实现，访问中间元素时间复杂度是OlogN；
	- 列表不能简单的调整某个元素的位置，有序列表可以（更改元素的分数）；
	- 有序集合更耗内存。

### Redis怎么统计在线用户
- 	Zset或者set：创建一个表来存储当前在线用户，有用户上线就用zadd，有用户离线就用zrem，统计当前在线人数就用zcard、
- 	Bitmap：有用户上线就set这一位，下线就清除这一位。

### 跳表怎么维护索引
- 查找操作：从head的最上面一层开始查找，如果下一个节点的值大于要查找的节点值或者为空值，就向下移动一层，一直找到下一个节点的值小于要查找的节点的值，找到之后就从这个节点的最上面一层开始查找，一直这样找下去。
- 删除操作：首先要找到这个数据，然后让这个数据最上层前序节点的指针指向后续节点的指针，然后再从前序节点的下一层开始继续向后查找，再找到这个节点，然后依次向下查找。
- 添加操作：通过随机数生成这个新的节点的层数，然后和查找操作一样，先找到应该插入节点的位置，并且在这个过程中记录最后一个下一节点的值大等于待插入节点值且小于等于这个层数的位置并存放到数组中。然后把这个数组中的每一个位置的下一节点都设置为新的节点的位置，新的节点的下一节点设置为数组中下一个节点的位置。

 
## Redis线程模型
### Redis 为什么是单线程的而不采用多线程方案？
redis的数据全都存放在内存中，CPU不是读取数据的瓶颈，而有可能是内存大小。如果使用多线程，则加锁反而可能会降低性能。

### 单线程的Redis为什么这么快？
- 	全部操作都是内存操作
- 	不涉及多线程的上下文切换
- 	采用非阻塞的IO复用模型
- 	数据结构简单

### 了解Redis的线程模型吗？ 
Redis6.0以前是单线程模型。
IO多路复用程序复杂监听多个套接字，将套接字产生的事件放入队列中排队，事件分派器每次从队列中取出一个事件，交给对应的事件处理器进行处理。
但是随着部分场景下对于QPS的需要越来越高，就引入了多线程，主要目的是充分利用CPU的多核资源和分摊同步IO的读写负荷。
多线程模型下，redis是有一个主线程用于执行命令，IO线程只用于读写socket。其中主线程先接收socket连接并且把socket连接请求放入到等待队列中，然后将其分配给IO线程，IO线程处理这些socket请求，主线程阻塞地等待IO完成，然后顺序地执行命令，把结果写道缓冲区，阻塞地等待IO线程把这些数据写回到socket中，然后清空队列。

### Redis对于大量的请求，是怎样处理的？
通过多路IO复用进行处理。

### Redis单线程的缺点以及影响
处理容易引起阻塞的操作时，用户体验比较差，比如会卡顿几秒钟的时间等待这个操作完成。
比如keys、hgetall、zrange等命令，而是使用scan代替。因为scan是基于游标的，每次查询时返回一个游标和少量的key，当再次调用的时候把游标传入，然后继续查找。也就是说把一个全局查找转为多次查找。



 
## Redis缓存
### 缓存中常说的热点数据和冷数据是什么？
热点数据就是会被频繁访问的数据，冷数据就是很少被访问的数据。
### Redis设置过期时间的两种方案是什么
首先，redis会为key设置一个过期时间，检查过期时间有两种方案：定期删除和惰性删除。
定期删除是每隔一定时间（默认是100ms）就随机抽取设置了过期时间的key，检查是否过期，如果过期就删除，如果过期的超过了1/4，就再来一遍。（随机抽取的原因是避免全局检查）
惰性删除是当下一次使用该数据时检查是否过期，如果过期就删除该数据。

### 定期和惰性一定能保证删除数据吗？如果不能，Redis会有什么应对措施？
不一定。定期删除未必能选到某些数据，惰性删除未必会访问到某些数据，所以内存可能会越来越高。因此redis有内存淘汰机制，对应的有八种内存淘汰策略。
- 	从已设置过期时间的数据集中选择最近最少使用的数据淘汰
- 	从已设置过期时间的数据集中选择将要过期的数据淘汰
- 	从已设置过期时间的数据集中任意选择数据淘汰
- 	从整个数据集中选择最近最少使用的数据淘汰
- 	从整个数据据中任意选择数据淘汰
- 	禁止淘汰数据，新写入操作会报错
- 	从设置了过期时间的key中，删除掉最不经常使用（使用次数最少）的key。
- 	从所有key中，删除掉最不经常使用（使用次数最少）的key。

### Redis中的LRU算法
Redis 2.8中给每个key增加了24bit的时间戳，会取出5个key，从中淘汰时间戳最小的一个。
Redis 3.0之后定义的LRU算法，首先定义一个淘汰池，大小为16的数组，从key中选出5个，然后将这个5个key放在池中，采样之后就更新，直到这个池子满了，在淘汰掉最少使用的key

### Redis中的LFU算法
在LRU算法的基础上，为每个数据增加一个计数器，后8bit表示数据的访问次数，前16bit表示上一次访问时间。先根据后8bit选择数据进行删除，如果相同就根据前16bit进行删除。但是最多只能记录到255，所以如果很多数据都是255，就会变成LRU算法。
- 	控制访问次数衰减。LFU 策略会计算当前时间和数据最近一次访问时间的差值，并把这个差值换算成以分钟为单位。然后，LFU 策略再把这个差值除以 lfu_decay_time 值，所得的结果就是数据 counter 要衰减的值。
- 	用计数器当前的值减去一个基数值，如果小于0，说明这个对象快不行了，那么就将其置为0，但是本次访问会使给这个变量续命，然后将新的值乘以配置项 lfu_log_factor 再加 1，再取其倒数，得到一个 p 值；然后，把这个 p 值和一个取值范围在（0，1）间的随机数 r 值比大小，只有 p 值大于 r 值时，计数器才加 1

### 假如MySQL有1000万数据，采用Redis作为中间缓存，取其中的10万，如何保证Redis中的数据都是热点数据？
采用上述的六种数据淘汰策略

### 缓存雪崩、缓存穿透、缓存预热、缓存更新、缓存击穿、缓存降级

- 缓存雪崩：
	- 大量缓存同一时间大面积失效，而新的缓存还没到来的时候，有了大量的新的请求，而由于内存中没有这些请求的缓存，因此这些请求都直接落在了数据库中，对数据库造成了巨大的压力，严重的会造成数据库宕机。
	- 解决办法：尽量保证redis的高可用性，选择合适的内存淘汰策略，通过加锁或者队列来控制读数据库写缓存的线程数量，将缓存过期时间设置为一个随机值，设置热点数据永不过期。
- 缓存穿透：
	- 黑客故意请求缓存中不存在的数据，那么就会去查询数据库，造成数据库在短时间内承受大量的请求而崩掉。
	- 解决办法：使用布隆过滤器，缓存空对象（存储层不命中之后，也把空值放入缓存中，同时设置一个很短的过期时间），增加校验
	- 使用布隆过滤器，适用于数据命中不高（可以过滤掉绝大多数的无效请求），实时性较低（因为哈希运算需要时间），缓存空间小（存位图比存数据缓存要小很多了），但是代码维护复杂
	- 使用空值缓存，适用于数据命中高，且实时性高的场景。
- 缓存预热
系统上线之后，先将常用缓存加载上来，而不是等待用户访问之后才加载，这一可以降低对于数据库的访问。
- 缓存更新
定期删除和惰性删除
- 缓存击穿
某个key非常热点，但是一旦过期，就会导致大量的访问瞬间全部落到数据库上，导致数据库宕机。方法就是把常用的热点key设置为永不过期即可。
- 缓存降级
当访问量剧增，服务出现问题或者非核心业务影响到核心业务时，需要降级处理，即对于非核心业务之间返回缓存中的数据，即使过期了，也不回到数据库中更新，而对于有些核心业务则不允许降级。

### 布隆过滤器
- 增加操作：要把某个值存入布隆过滤器，需要对其进行多次不同的哈希运算，并将位图中对应的所有的位全部置为1
- 查询操作：查询某个值是否在布隆过滤器中，同样需要对齐进行上面的多个哈希运算，然后查找对应的位图，只要有一个不是1，就说明这个数一定不在布隆过滤器中；如果全是1，则也不一定能保证一定在，因为可能会由于哈希冲突导致查询的所有位都被其他数据占用了。
- 优点：
	- 	用位图存储，占用内存小
	- 	增加和查询操作快，K个哈希函数的时间复杂度就是O(K)
- 缺点：
	- 	容易误判（增加哈希函数的个数可以减小误判率，同时也会增大位图的大小，原理就是减小了哈希冲突的概率）
	- 	无法删除

### 缓存与数据库双写时可能会出现的问题
- 	更新缓存操作都不可取，因为会出现线程安全问题，当AB同时更新一个数据时，都会出现脏读的问题
- 	先删除缓存，再更新数据库：
	- 	A写操作删除缓存
	- 	B读操作，发现缓存不在，从数据库中读出来
	- 	B把脏数据存入缓存
	- 	A把新值写入数据库
- 	先更新数据库，再删除缓存：
	- 	缓存刚好失效
	- 	请求A查询数据库，得一个旧值
	- 	请求B将新值写入数据库
	- 	请求B删除缓存
	- 	请求A将查到的旧值写入缓存

### 数据为什么会出现不一致的情况？
- 单库的情况下，A写B读操作并行进行，当A执行写操作时，第一步淘汰cache，但是此时卡住了，B读cache但是读不到，于是去访问数据库，从数据库在读出了一个脏数据，并更新到了cache中，这时A把数据写入到数据库，但是cache中的是脏数据。
- 主从同步读写分离时，A写B读操作并行进行，A淘汰cache，也成功更新到了主数据库中，B读操作访问cache，但是因为cache被淘汰，所以要读从数据库，但是还没主从同步成功，读出来脏数据，然后脏数据入cache。最后才完成主从同步。

### 如何保证缓存与数据库双写时的数据一致性
- 如果先删除缓存再更新数据，当删缓存之后，更新数据之前有新的请求过来，会把脏数据读到cache中，后续读的都是旧数据。
- 如果先更新数据库，再删除缓存，读取请求时再写回到缓存，当更新MySQL和删除缓存的这段时间，请求读取的还是旧数据，但是后来读取的就是新数据了。
- 缓存双淘汰法：先删除缓存，再写数据库，隔1s多再删除一次缓存中的这个数据。

https://www.cnblogs.com/Vincent-yuan/p/16052786.html
https://zhuanlan.zhihu.com/p/48334686/
https://www.likecs.com/show-305621921.html
### 如果数据量非常大，更新的数据量又很少怎么办？ 
- 使用AOF机制，设置更新数量的条件。
- 使用读写分离的集群。


 
## Redis的集群
### Redis的集群方案有几种？
- 	主从复制模式
- 	Sentinel（哨兵）模式
- 	Redis Cluster模式

### 为什么要使用主从模式？
单机的redis支持几万的QPS，更多的就无法支持了，但是读写分离模式可以支持10W+的QPS，对缓存来说都是读多写少，所以可以配置为一主多从的架构，master只接收写请求，然后同步到slave上，slave分担所有读请求。

### 主从同步问题
- 主从同步分为初次复制和断线后重复制。
- 其中初次复制分为同步和命令传播两部分，同步阶段是指从服务器连接到主服务器之后请求同步，主服务器执行BGSAVE，然后把生成的RDB文件发送给从服务器，同时把执行BGSAVE之后的所有命令全部记录到内存中，从服务器把接收到的BGSAVE更新到自己的内存之后会接收主服务器缓存的命令，然后执行这些命令保证主从之间数据库状态相同。之后的命令传播阶段是主服务器会把执行的每一条指令记录下来，并且发送给从服务器，从服务器执行这些命令保证和主服务器状态相同。
- 当主服务器和从服务器之间断开连接之后再连接，会触发重复制。主从服务器都会维护一个复制偏移量，记录发送了或者接收了多少个字节的数据，如果主从完全同步，这时的offset值完全相同。同时，主服务器还有一个复制积压缓冲区（默认1M），是一个固定长度FIFO队列，记录的是执行的每一个命令，再执行PSYNC时，会发送自己的offset，如果这个offset还在队列中，就会执行重复制，把队列中offset之后的命令全部同步到从服务器中。如果offset的数据已经没有了，就会执行初次复制。
- 另外每个服务器还会在启动时生成一个运行ID，主服务器会在初次复制时把自己的ID发送给从服务器，从服务器会把这个ID保存起来，当从服务器断线重连时，会像当前连接的主服务器发送这个ID，如果相同，就执行重复制，如果不相同就执行初次复制。

### 主从复制的步骤
- 从服务器设置主服务器地址和端口（SLAVEOF ip port）
- 建立套接字连接
- 从服务器发送ping命令确认是否连接并坚持主服务器能否正常处理请求。如果主服务器无法h回复或者从服务器无法接收，就重新建立连接。如果收到pong就说明可以正常复制。
- 身份验证。Auth命令，如果两个都没设置或者两个都设置了相同的密码，则验证成功，否则失败。
- 发送端口消息。Slave向master发送端口信息
- 同步，命令传播

### 心跳检测
- Slave默认每秒向master发送一个REPLCONF ACK命令，携带offset
	- 检测网络连接状态
	- 辅助实现min-slaves配置选项：
```
min-slaves-to-write 3		// 从服务器数量至少是3个
min-slaves-max-lag 10		// 三个从服务器延迟都大于或等于10
```
	- 进行命令同步，检测命令丢失

### 主从复制的优缺点？
- 优点：
	- master能自动将数据同步到slave，可以进行读写分离，分担master的读压力
	- master、slave之间的同步是以非阻塞的方式进行的，同步期间，客户端仍然可以提交查询或更新请求
- 缺点：
	- 不具备自动容错与恢复功能，master 节点宕机后，需要手动指定新的 master
	- master宕机，如果宕机前数据没有同步完，则切换IP后会存在数据不一致的问题
	- 因为每个节点存储的数据都是一样的，所以难以支持在线扩容，Redis的容量受限于单机配置
	- master宕机之后重新启动，由于这时master的数据库已经被清空，且设置了一个新的ID，这时slave请求同步时，也会清空slave的数据库。

### 哨兵模式
- 客户端连接到服务器时，先连接到哨兵节点，哨兵节点会告诉客户端主节点的地址，然后客户端连接到主节点。
- 哨兵节点会通过发送命令等待响应来监视所有的主从节点，一旦主节点宕机，就会推选出一个新的主节点，并且还会监视原来的主节点，一旦这个节点恢复，就让它作为新的主节点的从节点。
- 哨兵会每十秒一次获取主节点的信息，并且通过主服务器获取从节点的信息（从节点的IP和端口，监视是否有新的从节点上线），还要直接从从节点处获取从节点的相应信息，包括优先级偏移量等。
- 哨兵默认会每两秒给主从节点发送探测数据。
- 每个哨兵节点都以每秒钟一次的频率向所有的主从节点和哨兵发送ping，如果超出了一定的时间没有回复就会被标记为主观下线，有足够数量的节点认为主观下线，状态就会被解除。哨兵节点会选举出哨兵leader，负责故障转移。哨兵leader会推选出表现良好的从节点成为新的主节点，然后通知其他从节点更新主节点信息。

### 哨兵模式的功能
- 	集群监控： 负责监控 master 和 slave 是否正常工作；
- 	消息通知： 如果某个 redis 实例有故障， 哨兵负责发消息通知管理员；
- 	故障转移: 如果 master node 发生故障，会自动切换到 slave；
- 	配置中心：如果故障转移发生了，通知客户端新的 master 地址。

哨兵至少三个，保证自己的高可用；
哨兵+主从的部署架构是用来保证 redis 集群高可用的，并非保证数据不丢失；
哨兵(Sentinel)需要通过不断的测试和观察才能保证高可用。

### Sentinel（哨兵）模式的优缺点？
哨兵模式基于主从复制模式，增加了哨兵来监控与自动处理故障。
- 优点：
	- 哨兵模式基于主从复制模式，所以主从复制模式有的优点，哨兵模式也有
	- master 挂掉可以自动进行切换，系统可用性更高
- 缺点：
	- Redis的容量受限于单机配置
	- 需要额外的资源来启动sentinel进程

### Redis集群的原理是什么
集群可以部署多主多从，可以将数据自动切片，每个master上放一部分数据。提高内置的高可用支持，部分master不可用时还能继续工作。还需要开放一个端口用于cluster bus集群总线的节点间通信。

### 什么是一致性哈希？
一致性哈希是指对redis的key值做CRC16运算，然后对2^14取余，可以获得每个节点的slot，每个集群都会对应一定的slot，增加节点就意味着新的节点从一个已有的节点分担一部分slot，删除节点就意味着给一个节点增加一部分slot。

### 一致性哈希的优缺点
- 优点：
	- 无中心架构，支持动态扩容；
	- 数据按照slot存储分布在多个节点，节点间数据共享，可动态调整数据分布；
	- 高可用性。部分节点不可用时，集群仍可用。集群模式能够实现自动故障转移。
- 缺点：
	- 不支持批量操作（pipeline）。
	- 数据通过异步复制，不保证数据的强一致性。
	- 事务操作支持有限，只支持多key在同一节点上的事务操作，当多个key分布于不同的节点上时无法使用事务功能。
	- key作为数据分区的最小粒度，不能将一个很大的键值对象如hash、list等映射到不同的节点。
	- 不支持多数据库空间，单机下的Redis可以支持到16个数据库，集群模式下只能使用1个数据库空间。

### Redis集群怎样获取数据？
Client向集群中任意一个节点发送与数据库key有关的命令时，接受命令的节点会计算这个slot是否存储在本节点，如果在就返回数据，如果不在，就返回一个moved错误，指引client连接对应的槽的节点，用户还要再发送一次命令。

### Redis集群的gossip通信协议
- gossip 协议所有节点都持有一份元数据，不同节点的元数据发生了变更，就不断的将元数据发送给其他节点。
- 集中式的好处：元数据的读取和更新时效性很好，一旦元数据变化就更新到集中式存储，缺点就是元数据都在一个地方，可能导致元数据的存储压力。
- 对于 gossip 来说：元数据的更新会有延时，会降低元数据的压力，缺点是操作是元数据更新可能会导致集群的操作有一些滞后。

### redis cluster 主备切换与高可用
- 判断节点宕机：如果有一个节点认为另外一个节点宕机，那就是 pfail，主观宕机。如果多个节点认为一个节点宕机，那就是 fail，客观宕机。跟哨兵的原理一样；
- 对宕机的 master，从其所有的 slave 中选取一个切换成 master node，在此之前会进行一次过滤，检查每个 slave 与 master 的断开时间，如果超过了一个时间就说明这个节点可能已经宕机了，就没有资格切换成 master；
- 从节点选取：每个从节点都会根据从 master 复制数据的 offset，来设置一个选举时间，offset 越大的从节点，选举时间越靠前，master node 开始给 slave 选举投票，如果一半以上投给了某个 slave，那么选举通过；（选offset大的）

### Redis Cluster 模式的优缺点？
实现了Redis的分布式存储，即每台节点存储不同的内容，来解决在线扩容的问题。
- 优点：
	- 无中心架构，数据按照slot分布在多个节点
	- 集群中的每个节点都是平等的，只需要连接集群中的任意一个节点，就可以获取到其他节点的数据。
	- 可线性扩展到1000多个节点，节点可动态添加或删除
	- 能够实现自动故障转移，节点之间通过gossip协议交换状态信息，用投票机制完成slave到master的角色转换
- 缺点：
	- 数据通过异步复制，不保证数据的强一致性
	- slave充当 “冷备”，不对外提供读、写服务，只作为故障转移使用。
	- 批量操作限制，目前只支持具有相同slot值的key执行批量操作，对mset、mget、sunion等操作支持不友好
	- key事务操作支持有限，只支持多key在同一节点的事务操作，多key分布在不同节点时无法使用事务功能
	- 不支持多数据库空间，一台redis可以支持16个db，集群模式下只能使用一个，即db 0。Redis Cluster模式不建议使用pipeline和multi-keys操作，减少max redirect产生的场景。

### 哨兵模式下的脑裂问题
当master和其他的slave之间断开连接后，slave认为master宕机，重新选举新的master，这样就会出现两个master，但是client连接的还是原来的master， 分别进行数据的读写，会导致出现冲突导致数据丢失。

### 异步复制的数据丢失问题
主从复制是异步的，不能保证刚写到master的数据就立即写到slave，如果在这期间master宕机了，会丢失这一部分的数据。

### 怎样解决脑裂问题导致的数据丢失
```
min-slaves-to-write 3
min-slaves-max-lag 10
```
对于脑裂问题，一旦master宕机，而其他的slave重新选举了一个新的master，这时原来的master会触发上面的条件，然后拒绝任何客户端的写入，这样就避免了数据的丢失。

### Raft协议
只要一个节点在一个随机的指定时间内没有收到requestvote或者appendentries，就说明这段超时时间内没有发现leader，那么自己就成为candidate，开始竞选leader。
- 	增加自己的term。
- 	启动一个新的定时器。
- 	给自己投一票。
- 	向所有其他节点发送RequestVote，并等待其他节点的回复。
各follower节点只能投一票，即投给收到的第一个requestVote包的那个节点，

### redis的sentinel上投票选举的问题
某个哨兵认定master客观下线之后，会先看自己有没有投过票，如果投过了就在一定时间内不会成为leader，如果还没有投票，就成为candidate。接下来会将更新故障转移状态设置为start，并且将当前的epoch加1，更新自己的超时时间为当前时间加上一个随机时间，向其他节点发送包括自己epoch的请求投票，然后给自己投一票。投票的方式就是把自己的leader字段和leader_epoch字段改为它想要投的leader的相应信息。当有一半的用户认同某个哨兵作为节点的时候，该哨兵就成为了主节点。当其他的哨兵检测到master在线之后，会去掉客观下线的标记。



 
## Redis持久化
### Redis持久化机制？
- 目的：为了保持数据的持久性，由于redis把数据存放在内存中，所以当redis宕机之后，再次重启时，由于没有把内存中的数据落到磁盘上，因此会造成这一部分数据的丢失，所以需要一个持久化机制，把数据高效地写入到磁盘上，同时还不能过于影响redis的性能。
- 有RDB和AOF两种持久化机制：
- RDB机制：可以通过save或bgsave命令创建一个RDB文件，其中save命令创建文件是直接阻塞服务器进程，而bgsave是由主进程创建一个子进程，然后子进程进行RDB文件的写入，父进程继续处理来自客户端的命令。可以定义多久之内更改了多少条命令之后就写一次RDB。缺点：存储频率高则效率低，频率低则同步不及时，如果数据比较多则备份需要时间长。优点：恢复数据快
- AOF机制：AOF的实时性更好，AOF是把服务器所执行的写命令全部保存下来，可以设置为每执行一条命令就写一次、每秒写一次和永远不写。常用每秒写一次。当恢复数据时，因为redis的命令必须要由客户端发出来，所以需要首先创建一个伪客户端，这个伪客户端不断地读RDB，然后向服务器发出请求。缺点：数据恢复时间长。优点：数据存储到磁盘效率高，占用磁盘空间小。AOF 日志文件通过非常可读的方式进行记录，这个特性适合做灾难性的误操作的紧急恢复，比如不小心使用 flushall 清空了所有数据，只要 rewrite 没有发生，就可以立即拷贝 AOF，将最后一条 flushall 命令删除，再回放 AOF 恢复数据。

### AOF重写了解吗？ 
- AOF重写可以覆盖原来的文件，从而得到一个比原来文件更小，记录更少的文件。通过读取数据库中的键值对进行重写。
- 在执行AOF重写时，需要创建一个缓冲区用于记录重写期间的新的请求，重写结束之后，会用新的AOF文件替换原来的AOF文件，并且将缓存区中的数据全部增加到新的AOF中

### 如何解决Redis的并发竞争Key问题


### 常见的数据优化方案你了解吗？




## redis操作
https://www.cnblogs.com/antLaddie/p/15362191.html
### redis基础操作
- 连接服务端：
`./redis-cli -h 127.0.0.1 -p 6379`
- Redis默认是有16个数据库的（0~15）通过select命令来切换数据库
`    select 1    -- 连接到第 2 个数据库 0开始计算`
- 往数据库设置string类型值
`    set name zhangsan`
- 查看数据库中key的数量
`    dbsize`
- 查看刚才添加的key的值
`    get name`
- 查看所有key的值
`    keys *`
- 清空全部数据库和清空当前库
`    flushall（清空全部库） flushdb（清空当前库） ` 
- 删除添加的name key键
`    del name`

### 常用键值操作
- keys pattern：查询满足pattern的键
- del key：删除指定的key
- unlink key：删除，会返回删除的数量
- exits key：查询是否存在
- type key：返回当前key的类型
- rename key newkey：重命名
- renamenx key newkey：重命名，如果存在在覆盖，不存在则报错
- copy source dest [db destination-db] [replace]：拷贝当前值，如果是拷贝到当前列表，则后面不需要加什么，如果是拷贝到其他表中，后面需要加上其他表的标号，replace表示强制替换
- expire key seconds []：设置过期时间
- pexpire key milliseconds []：设置过期时间
- expireat key timestamp []：设置过期时间的时间戳
- pexpireat key milliseconds-timestamp []：设置过期时间的时间戳
- persist key：清除当前有定时时间的键值，设置永不过期
- ttl key：查看当前有定时key的剩余时间，返回秒
- pttl key：查看当前有定时key的剩余时间，返回毫秒
- move key db：把指定的键值移动到选定的数据库db当中

### 概述
- set类型的都是用来设置键值对的
- mset是用来设置多个键值对
- get类型用户获取值
- 带nx后缀的是用来表示当前存在则添加失败
- 带p前缀的用于设置微秒超时时间
- 带ex后缀的用来设置超时时间

### string类型命令
- set key value [ex seconds|px milliseconds|exat timestamp|pxat milliseconds-timestamp|keepttl] [nx|xx] [get]：
	- nx：只有键key不存在的时候才会设置key的值
	- xx：只有键key存在的时候才会设置key的值
	- get：返回 key 存储的值，如果 key 不存在返回空
- setnx key value：设置键值，存在此键则返回0不覆盖，否则正常设置
- setrange key offset value：偏移量offset>=0开始， 用value参数覆盖键key储存的字符串值
- strlen key：获取指定key所储存的字符串值的长度。
- append key value：用于为指定的key追加值，成功后返回当前键里面的字符串全部长度
- get key：如果键key不存在，那么返回特殊值nil；否则返回键key的值。
- getdel key：先获取，再删除，返回值
- getset key value：设置更新key值，设置前先把原有的值返回出来，并设置新的值
- getrange key start end：取范围
- getex key [ex seconds|px milliseconds|exat timestamp|pxat milliseconds-timestamp|persist]：获取指定的key值，并且获取后可以对当前key设置超时时间或者清除超时时间
- mset key value [key value ...]：设置多个
- mget key [key ...]：获取多个
- setex key seconds value：设置键值对并设置超时时间
- incr key：将key中储存的数字值增一，并返回增加后的值
- incrby key increment：将key中储存的数字值增加指定步长increment，并返回增加后的值

### 哈希类型命令
- hset key field value [field value ...]：用于为存储在key中的哈希表的field字段赋值value，可以添加多个，和hmset一样
- get key field
- hdel key field [field ...]
- hgetall key
- hexists key field
- hkeys key：返回存储在key中哈希表的所有field
- hvals key：返回存储在key中哈希表的所有value
- hscan key cursor [match pattern] [count count]：用于遍历哈希表中的键值对

### list类型命令
- lpush lpop rpush rpop lrange（遍历）
- 带有x后缀的表示如果没有这个key就不插入，不带后缀的表示创建新的key
- b开头表示阻塞的
- llen key：获取到集合里元素的总个数
- lindex key index：返回集合key里索引index位置存储的元素，0~n从左往右索引、-1~-n从右往左索引
- lrem key count element：从集合key中删除前count个值等于element的元素
- lset key index element：设置集合key中index位置的元素值为新的element
- linsert key before|after pivot element：把element元素插入到指定集合key里，但是还要以pivot内部的一个元素为基准，看是插到这个元素的左边还是右边
- lpos key element [rank rank] [count num-matches] [maxlen len]：返回集合key中匹配给定element成员的索引
- lmove source destination left|right left|right：用于原子地从source集合左边或者右边弹出一个元素，添加到destination新集合里的左边或右边

### set
- sadd（增加） smembers （遍历）srem（移除）
- sdiff key [key ...]:返回第一个集合与其它集合之间的差异；说白就是第一个集合的某个元素在其它集合都不存在则这个元素会被返回
- sdiffstore destination key [key ...]：此命令和sdiff功能差不多，不同的是它将结果保存到destination集合，并返回成功添加到新集合上的个数。
- sinter key [key ...]：交集
- sunion key [key ...]：并集
- scard key：返回集合中元素的数量（整型值）
- smembers key：返回存储在key中的集合的所有的成员
- sismember key member：判断元素member是否是集合key的成员

### sortedset
- zadd key [nx|xx] [gt|lt] [ch] [incr] score member [score member ...]
	- nx：只能做添加操作
    - xx：只能做更新操作
    - gt：更新的元素分数必须比原分数大
    - lt：更新的元素分数必须比原分数小
    - ch：返回添加和更新成功的个数
    - incr：累加操作，score代表更新member的步长
- zrange key min max [byscore|bylex] [rev] [limit offset count] [withscores]
	- byscore：按照分数排序
	- bylex：按照ASCII排序
	- rev：设置倒序排列，这时的min和max要倒过来写
	- limit offset count：筛选后的结果排序
	- withscores：最终查询结果显示分数
- zinter numkeys key [key ...] [weights weight [weight ...]] [aggregate sum|min|max] [withscores]
	- 计算numkeys个有序集合的交集
	- aggregate sum|min|max：可以指定交集、并集的结果集的聚合方式。指定sum（默认）则交集的元素的分数结合，若指定max，则会选择最大的作为交集的分数
- zunion numkeys key [key ...] [weights weight [weight ...]] [aggregate sum|min|max] [withscores]
	- 计算给定的numkeys个有序集合的并集，并且返回结果
- 








### 修改配置文件
- 	bind：redis只能接收来自该IP地址的请求
- 	protected-mode 为no时才允许外部访问
- 	daemonize是否是守护进程
- 	pidfile设置为守护进程时pidfile的存储目录
- 	logfile log日志的级别
- 	databases 设置默认的数据库数目
- 	maxmemory <bytes> 来设定最大内存（当数据内存达到 maxmemory 时，便会触发redis的内存淘汰策略。该参数通常设定为其物理内存的四分之三。
- 	maxmemory-policy 来指定使用哪种内存淘汰策略
- 	maxmemory-samples 选项配置每次会随机选择多少个key放入淘汰池中

